Facial recognition systems are becoming increasingly useful in real world applications such as authentication of a person's identity. 
However, one of the largest problems of face recognition technology is the security. As we all know, most famous face recognition algorithms are using deep learning models. Recent research has shown that the deep learning models are susceptible to adversarial inputs despite the fact that these deep learning models have achieved a great success in face recognition compared to traditional machine learning models. 

Unlike other adversarial attacks which intentionally add imperceptible noises to fool the deep learning models, in this dissertation we conduct physically 
realizable attacks on the facial recognition system. We treat the recognition system as a black box (we do not have any information on the model). Our attack strategy will work on any recognition system, thereby revealing the vulnerabilities inherent in such systems. 
In particular, we carry out three types of attack: break-in, impersonation and evasion.